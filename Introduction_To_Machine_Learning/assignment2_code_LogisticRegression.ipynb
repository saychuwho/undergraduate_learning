{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 책에서처럼 일단 공동 import를 하자\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "# 불필요한 warning이 나오지 않도록 하는 곳\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression을 활용할 예정\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 784) (70000,)\n"
     ]
    }
   ],
   "source": [
    "# mnist 데이터셋을 불러오자\n",
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784')\n",
    "print(mnist.data.shape, mnist.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "pixel1      0.0\n",
      "pixel2      0.0\n",
      "pixel3      0.0\n",
      "pixel4      0.0\n",
      "pixel5      0.0\n",
      "           ... \n",
      "pixel780    0.0\n",
      "pixel781    0.0\n",
      "pixel782    0.0\n",
      "pixel783    0.0\n",
      "pixel784    0.0\n",
      "Name: 0, Length: 784, dtype: float64\n",
      "<class 'pandas.core.series.Series'>\n",
      "0        5\n",
      "1        0\n",
      "2        4\n",
      "3        1\n",
      "4        9\n",
      "        ..\n",
      "69995    2\n",
      "69996    3\n",
      "69997    4\n",
      "69998    5\n",
      "69999    6\n",
      "Name: class, Length: 70000, dtype: category\n",
      "Categories (10, object): ['0', '1', '2', '3', ..., '6', '7', '8', '9']\n"
     ]
    }
   ],
   "source": [
    "# mnist 데이터셋 속 숫자들은 어떻게 구성이 되어있는가?\n",
    "print(type(mnist.data))\n",
    "print(type(mnist.data.loc[0]))\n",
    "print(mnist.data.loc[0])\n",
    "print(type(mnist.target))\n",
    "print(mnist.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x11b8aa6a7d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# mnist set들을 출력해보자\n",
    "# mnist set을 출력하기 위해서는 mnist set을 numpy로 바꾼 후에 plt로 출력해야 한다.\n",
    "\n",
    "image = mnist.data.to_numpy()\n",
    "\n",
    "plt.subplot(431)\n",
    "plt.imshow((image[0].reshape(28,28)), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "\n",
    "plt.subplot(432)\n",
    "plt.imshow((image[1].reshape(28,28)), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "\n",
    "plt.subplot(433)\n",
    "plt.imshow((image[2].reshape(28,28)), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "\n",
    "plt.subplot(434)\n",
    "plt.imshow((image[3].reshape(28,28)), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "\n",
    "plt.subplot(435)\n",
    "plt.imshow((image[4].reshape(28,28)), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "\n",
    "plt.subplot(436)\n",
    "plt.imshow((image[5].reshape(28,28)), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7000, 784)\n",
      "(63000, 784)\n",
      "(7000,)\n",
      "(63000,)\n"
     ]
    }
   ],
   "source": [
    "# train set과 test set을 분리해야 한다.\n",
    "# train과 test set을 그냥 numpy형태로 다 바꿔서 귀찮게 하지 말자.\n",
    "from sklearn.model_selection import train_test_split\n",
    "mnist_data = mnist.data.to_numpy()\n",
    "mnist_target = mnist.target.to_numpy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(mnist_data, mnist_target, test_size=0.9, random_state=0)\n",
    "# 잘 나뉘었는가 확인\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 기록\n",
    "##### 이전 기록\n",
    "- 디폴트 100번도 안되고 1000번도 max_iter를 늘리라고 해서 10000번으로 늘려봤다.\n",
    "- 계속 해도 converge 되지 않아서 train data / test data의 사이즈를 0.9/0.1에서 기본값인 0.75/0.25로 줄였다.\n",
    "- 그래도 converge 되지 않아서 tol을 기본값인 1e-4에서 1e-3으로 줄였다.\n",
    "- 그래도 converge 되지 않아서 tol값에 변화를 주지 말고 L2 규제 계수 C=0.1로 두었다\n",
    "- 그래도 converge 되지 않아서 tol값에 변화를 주지 말고 L2 규제 계수 C=0.01로 두었다.\n",
    "- 시간이 너무 오래 걸려서 solver를 saga로 바꾸고, l1 규제를 적용했다. max_iter랑 C는 기본값으로 두었다.\n",
    "- 그래도 converge 되지 않아서 max_iter를 1000번, C=0.1로 두고 다시 돌려보았다.\n",
    "- 큰 차이가 없는거 같은데... 시간이 더 오래 걸리고.... 그냥 n_jobs를 넣지 말자. 그리고 코랩에서 돌리면 되지 않을까.\n",
    "- train set의 크기를 7000개로 줄여서 다시 시도. n_jobs=-1로 두고. >> 확실히 학습하는 시간이 대폭 줄기는 했다. 다른 모델들도 이렇게 해야 겠다.\n",
    "- 다른 모델들은 학습시간이 겁나 짧은데 너는 왜그러는 거니???\n",
    "- scikit-learn에서 찾은 바로는 거기서도 샘플을 5000개로 사용하고, tol=0.1로 주었다. 이대로 해볼까. \n",
    "- tolorence가 문제였구먼 이거...... 일단 tol=0.1을 고정을 해놔야 엥간한 상황에서 converge가 된다.\n",
    "- tol을 최대한 줄이면 어디까지 갈 수 있나? >> 0.0025까지는 줄일 수 있다.\n",
    "##### penalty='l1', C=0.1, solver='saga', tol=0.1 일때\n",
    "- train accuracy : 0.929 test accuracy : 0.905\n",
    "##### penalty='l1', C=0.1, solver='saga', max_iter=5000, tol=0.005\n",
    "- tol=0.005, max_iter=5000으로 잡고 계산하면 된다. 이러면 한 모델당 50초 정도 시간이 걸린다.\n",
    "##### penalty='l1', C=0.1, solver='saga', max_iter=5000, tol=0.0025\n",
    "- 이렇게 세팅하면 한 모델당 학습 시간이 2분 걸린다.\n",
    "- 이게 마지노선일듯. 여기서 C값의 변화에 따라 어떻게 정확도가 높아지는지, penalty를 어떻게 주느냐에 따라 결과가 달라지는 지를 기록해보자.\n",
    "##### penalty='l1'으로 고정하고 C값을 log scale로 변화를 줘가며 학습시켜 train accuracy와 test accuracy를 구해보자\n",
    "- c=0.001일때 test accuracy : 0.896으로 가장 높다. 또한 train accuracy : 0.929로 과적합 되지도 않았다. \n",
    "##### penalty='l2'으로 고정하고 C값을 log scale로 변화를 줘가며 학습시켜 train accuracy와 test accuracy를 구해보자\n",
    "- c=0.00001일때 test accuracy 0.9, train accuracy 0.966으로 제일 결과가 좋았다. \n",
    "- 만약에 c 값이 적으면 적을수록 올라간다면 어디까지 걸어야 할까?\n",
    "- c=1e-6에서 train accuracy 0.933, test accuracy 0.905로 늘어났다. 그 이후 값들은 모두 c=1e-6보다 안좋다.\n",
    "##### penalty=elasticnet으로 설정하고, l1_ratio를 0.1 단위로 조절해가면서 학습한 모델들의 정확도를 확인해보자.\n",
    "- l1_ratio에 따라서 계산했을때는 모두 c=1e-6, test accuracy 0.905, train accuracy 0.933이다.\n",
    "- l1 ratio에 따른 경향은 크게 없었다. \n",
    "##### 결론\n",
    "- 각각을 테스트해보았을때 l2를 사용했을 때 최적의 결과가 가장 좋은 모델이었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of C=100 calculated\n",
      "accuracy of C=10 calculated\n",
      "accuracy of C=1 calculated\n",
      "accuracy of C=0.1 calculated\n",
      "accuracy of C=0.01 calculated\n",
      "accuracy of C=0.001 calculated\n",
      "accuracy of C=0.0001 calculated\n",
      "accuracy of C=1e-05 calculated\n",
      "accuracy of C=1e-06 calculated\n",
      "accuracy of C=1e-07 calculated\n",
      "accuracy of C=1e-08 calculated\n"
     ]
    }
   ],
   "source": [
    "# penalty를 적용한 후 model을 C값에 따라 학습\n",
    "# l1으로 적용한 후 계산해보고, 이후 l2로 바꾸어서 계산, 마지막으로는 'elasticnet'으로 계산. 이때 l1_ratio에 대한 적용은 나중에 다뤄보자\n",
    "# l1 적용해보고, l2 적용해봐야 함.\n",
    "Penalty = 'l2'\n",
    "log_models = []\n",
    "log_train_score = []\n",
    "log_test_score = []\n",
    "C_list = [100, 10, 1, 0.1, 0.01, 0.001, 0.0001, 0.00001,1e-06, 1e-07, 1e-08]\n",
    "for c in C_list:\n",
    "    logModel = LogisticRegression(penalty=Penalty, C=c, solver='saga', max_iter=5000, tol=0.0025, n_jobs=-1)\n",
    "    logModel.fit(X_train, y_train)\n",
    "    log_train_score.append(logModel.score(X_train, y_train))\n",
    "    log_test_score.append(logModel.score(X_test, y_test))\n",
    "    log_models.append(logModel)\n",
    "    print(\"accuracy of C={} calculated\".format(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c=100 / train accuracy : 0.995 / test accuracy : 0.8854920634920634 \n",
      "\n",
      "c=10 / train accuracy : 0.9947142857142857 / test accuracy : 0.8855238095238095 \n",
      "\n",
      "c=1 / train accuracy : 0.9948571428571429 / test accuracy : 0.8854603174603175 \n",
      "\n",
      "c=0.1 / train accuracy : 0.9947142857142857 / test accuracy : 0.8855873015873016 \n",
      "\n",
      "c=0.01 / train accuracy : 0.9945714285714286 / test accuracy : 0.8856031746031746 \n",
      "\n",
      "c=0.001 / train accuracy : 0.9945714285714286 / test accuracy : 0.8862063492063492 \n",
      "\n",
      "c=0.0001 / train accuracy : 0.9894285714285714 / test accuracy : 0.8892380952380953 \n",
      "\n",
      "c=1e-05 / train accuracy : 0.9655714285714285 / test accuracy : 0.9003333333333333 \n",
      "\n",
      "c=1e-06 / train accuracy : 0.9332857142857143 / test accuracy : 0.9046825396825396 \n",
      "\n",
      "c=1e-07 / train accuracy : 0.8964285714285715 / test accuracy : 0.8853492063492063 \n",
      "\n",
      "c=1e-08 / train accuracy : 0.8457142857142858 / test accuracy : 0.8368571428571429 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train score와 test score를 출력하자\n",
    "for c, trainScore, testScore in zip(C_list,log_train_score, log_test_score):\n",
    "    print(\"c={} / train accuracy : {} / test accuracy : {} \\n\".format(c, trainScore, testScore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating l1_ratio=0.1\n",
      "accuracy of C=100 calculated\n",
      "accuracy of C=10 calculated\n",
      "accuracy of C=1 calculated\n",
      "accuracy of C=0.1 calculated\n",
      "accuracy of C=0.01 calculated\n",
      "accuracy of C=0.001 calculated\n",
      "accuracy of C=0.0001 calculated\n",
      "accuracy of C=1e-05 calculated\n",
      "accuracy of C=1e-06 calculated\n",
      "accuracy of C=1e-07 calculated\n",
      "accuracy of C=1e-08 calculated\n",
      "accuracy of l1_ratio=0.1 calculated\n",
      "calculating l1_ratio=0.2\n",
      "accuracy of C=100 calculated\n",
      "accuracy of C=10 calculated\n",
      "accuracy of C=1 calculated\n",
      "accuracy of C=0.1 calculated\n",
      "accuracy of C=0.01 calculated\n",
      "accuracy of C=0.001 calculated\n",
      "accuracy of C=0.0001 calculated\n",
      "accuracy of C=1e-05 calculated\n",
      "accuracy of C=1e-06 calculated\n",
      "accuracy of C=1e-07 calculated\n",
      "accuracy of C=1e-08 calculated\n",
      "accuracy of l1_ratio=0.2 calculated\n",
      "calculating l1_ratio=0.30000000000000004\n",
      "accuracy of C=100 calculated\n",
      "accuracy of C=10 calculated\n",
      "accuracy of C=1 calculated\n",
      "accuracy of C=0.1 calculated\n",
      "accuracy of C=0.01 calculated\n",
      "accuracy of C=0.001 calculated\n",
      "accuracy of C=0.0001 calculated\n",
      "accuracy of C=1e-05 calculated\n",
      "accuracy of C=1e-06 calculated\n",
      "accuracy of C=1e-07 calculated\n",
      "accuracy of C=1e-08 calculated\n",
      "accuracy of l1_ratio=0.30000000000000004 calculated\n",
      "calculating l1_ratio=0.4\n",
      "accuracy of C=100 calculated\n",
      "accuracy of C=10 calculated\n",
      "accuracy of C=1 calculated\n",
      "accuracy of C=0.1 calculated\n",
      "accuracy of C=0.01 calculated\n",
      "accuracy of C=0.001 calculated\n",
      "accuracy of C=0.0001 calculated\n",
      "accuracy of C=1e-05 calculated\n",
      "accuracy of C=1e-06 calculated\n",
      "accuracy of C=1e-07 calculated\n",
      "accuracy of C=1e-08 calculated\n",
      "accuracy of l1_ratio=0.4 calculated\n",
      "calculating l1_ratio=0.5\n",
      "accuracy of C=100 calculated\n",
      "accuracy of C=10 calculated\n",
      "accuracy of C=1 calculated\n",
      "accuracy of C=0.1 calculated\n",
      "accuracy of C=0.01 calculated\n",
      "accuracy of C=0.001 calculated\n",
      "accuracy of C=0.0001 calculated\n",
      "accuracy of C=1e-05 calculated\n",
      "accuracy of C=1e-06 calculated\n",
      "accuracy of C=1e-07 calculated\n",
      "accuracy of C=1e-08 calculated\n",
      "accuracy of l1_ratio=0.5 calculated\n",
      "calculating l1_ratio=0.6000000000000001\n",
      "accuracy of C=100 calculated\n",
      "accuracy of C=10 calculated\n",
      "accuracy of C=1 calculated\n",
      "accuracy of C=0.1 calculated\n",
      "accuracy of C=0.01 calculated\n",
      "accuracy of C=0.001 calculated\n",
      "accuracy of C=0.0001 calculated\n",
      "accuracy of C=1e-05 calculated\n",
      "accuracy of C=1e-06 calculated\n",
      "accuracy of C=1e-07 calculated\n",
      "accuracy of C=1e-08 calculated\n",
      "accuracy of l1_ratio=0.6000000000000001 calculated\n",
      "calculating l1_ratio=0.7000000000000001\n",
      "accuracy of C=100 calculated\n",
      "accuracy of C=10 calculated\n",
      "accuracy of C=1 calculated\n",
      "accuracy of C=0.1 calculated\n",
      "accuracy of C=0.01 calculated\n",
      "accuracy of C=0.001 calculated\n",
      "accuracy of C=0.0001 calculated\n",
      "accuracy of C=1e-05 calculated\n",
      "accuracy of C=1e-06 calculated\n",
      "accuracy of C=1e-07 calculated\n",
      "accuracy of C=1e-08 calculated\n",
      "accuracy of l1_ratio=0.7000000000000001 calculated\n",
      "calculating l1_ratio=0.8\n",
      "accuracy of C=100 calculated\n",
      "accuracy of C=10 calculated\n",
      "accuracy of C=1 calculated\n",
      "accuracy of C=0.1 calculated\n",
      "accuracy of C=0.01 calculated\n",
      "accuracy of C=0.001 calculated\n",
      "accuracy of C=0.0001 calculated\n",
      "accuracy of C=1e-05 calculated\n",
      "accuracy of C=1e-06 calculated\n",
      "accuracy of C=1e-07 calculated\n",
      "accuracy of C=1e-08 calculated\n",
      "accuracy of l1_ratio=0.8 calculated\n",
      "calculating l1_ratio=0.9\n",
      "accuracy of C=100 calculated\n",
      "accuracy of C=10 calculated\n",
      "accuracy of C=1 calculated\n",
      "accuracy of C=0.1 calculated\n",
      "accuracy of C=0.01 calculated\n",
      "accuracy of C=0.001 calculated\n",
      "accuracy of C=0.0001 calculated\n",
      "accuracy of C=1e-05 calculated\n",
      "accuracy of C=1e-06 calculated\n",
      "accuracy of C=1e-07 calculated\n",
      "accuracy of C=1e-08 calculated\n",
      "accuracy of l1_ratio=0.9 calculated\n"
     ]
    }
   ],
   "source": [
    "# elasticnet의 경우는 l1_ratio에 따라 그 결과를 뽑아야 하니 model을 따로 묶어서 담을만한 곳이 필요하다.\n",
    "Penalty = 'elasticnet'\n",
    "logmodel_elasticent = []\n",
    "train_score_elasticent = []\n",
    "test_score_elasticent = []\n",
    "l1_ratio_list = [0.1*i for i in range(1,10)]\n",
    "for l1_R in l1_ratio_list:\n",
    "    print(\"calculating l1_ratio={}\".format(l1_R))\n",
    "    for c in C_list:\n",
    "        logModel = LogisticRegression(penalty=Penalty, C=c, solver='saga', max_iter=5000, tol=0.0025, n_jobs=-1, l1_ratio=l1_R)\n",
    "        logModel.fit(X_train, y_train)\n",
    "        log_train_score.append(logModel.score(X_train, y_train))\n",
    "        log_test_score.append(logModel.score(X_test, y_test))\n",
    "        log_models.append(logModel)\n",
    "        print(\"accuracy of C={} calculated\".format(c))\n",
    "    logmodel_elasticent.append(log_models)\n",
    "    train_score_elasticent.append(log_train_score)\n",
    "    test_score_elasticent.append(log_test_score)\n",
    "    print(\"accuracy of l1_ratio={} calculated\".format(l1_R))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1_ratio=0.1 c=100 / train accuracy : 0.995 / test accuracy : 0.8854920634920634 \n",
      "\n",
      "l1_ratio=0.1 c=10 / train accuracy : 0.9947142857142857 / test accuracy : 0.8855238095238095 \n",
      "\n",
      "l1_ratio=0.1 c=1 / train accuracy : 0.9948571428571429 / test accuracy : 0.8854603174603175 \n",
      "\n",
      "l1_ratio=0.1 c=0.1 / train accuracy : 0.9947142857142857 / test accuracy : 0.8855873015873016 \n",
      "\n",
      "l1_ratio=0.1 c=0.01 / train accuracy : 0.9945714285714286 / test accuracy : 0.8856031746031746 \n",
      "\n",
      "l1_ratio=0.1 c=0.001 / train accuracy : 0.9945714285714286 / test accuracy : 0.8862063492063492 \n",
      "\n",
      "l1_ratio=0.1 c=0.0001 / train accuracy : 0.9894285714285714 / test accuracy : 0.8892380952380953 \n",
      "\n",
      "l1_ratio=0.1 c=1e-05 / train accuracy : 0.9655714285714285 / test accuracy : 0.9003333333333333 \n",
      "\n",
      "l1_ratio=0.1 c=1e-06 / train accuracy : 0.9332857142857143 / test accuracy : 0.9046825396825396 \n",
      "\n",
      "l1_ratio=0.1 c=1e-07 / train accuracy : 0.8964285714285715 / test accuracy : 0.8853492063492063 \n",
      "\n",
      "l1_ratio=0.1 c=1e-08 / train accuracy : 0.8457142857142858 / test accuracy : 0.8368571428571429 \n",
      "\n",
      "l1_ratio=0.2 c=100 / train accuracy : 0.995 / test accuracy : 0.8854920634920634 \n",
      "\n",
      "l1_ratio=0.2 c=10 / train accuracy : 0.9947142857142857 / test accuracy : 0.8855238095238095 \n",
      "\n",
      "l1_ratio=0.2 c=1 / train accuracy : 0.9948571428571429 / test accuracy : 0.8854603174603175 \n",
      "\n",
      "l1_ratio=0.2 c=0.1 / train accuracy : 0.9947142857142857 / test accuracy : 0.8855873015873016 \n",
      "\n",
      "l1_ratio=0.2 c=0.01 / train accuracy : 0.9945714285714286 / test accuracy : 0.8856031746031746 \n",
      "\n",
      "l1_ratio=0.2 c=0.001 / train accuracy : 0.9945714285714286 / test accuracy : 0.8862063492063492 \n",
      "\n",
      "l1_ratio=0.2 c=0.0001 / train accuracy : 0.9894285714285714 / test accuracy : 0.8892380952380953 \n",
      "\n",
      "l1_ratio=0.2 c=1e-05 / train accuracy : 0.9655714285714285 / test accuracy : 0.9003333333333333 \n",
      "\n",
      "l1_ratio=0.2 c=1e-06 / train accuracy : 0.9332857142857143 / test accuracy : 0.9046825396825396 \n",
      "\n",
      "l1_ratio=0.2 c=1e-07 / train accuracy : 0.8964285714285715 / test accuracy : 0.8853492063492063 \n",
      "\n",
      "l1_ratio=0.2 c=1e-08 / train accuracy : 0.8457142857142858 / test accuracy : 0.8368571428571429 \n",
      "\n",
      "l1_ratio=0.30000000000000004 c=100 / train accuracy : 0.995 / test accuracy : 0.8854920634920634 \n",
      "\n",
      "l1_ratio=0.30000000000000004 c=10 / train accuracy : 0.9947142857142857 / test accuracy : 0.8855238095238095 \n",
      "\n",
      "l1_ratio=0.30000000000000004 c=1 / train accuracy : 0.9948571428571429 / test accuracy : 0.8854603174603175 \n",
      "\n",
      "l1_ratio=0.30000000000000004 c=0.1 / train accuracy : 0.9947142857142857 / test accuracy : 0.8855873015873016 \n",
      "\n",
      "l1_ratio=0.30000000000000004 c=0.01 / train accuracy : 0.9945714285714286 / test accuracy : 0.8856031746031746 \n",
      "\n",
      "l1_ratio=0.30000000000000004 c=0.001 / train accuracy : 0.9945714285714286 / test accuracy : 0.8862063492063492 \n",
      "\n",
      "l1_ratio=0.30000000000000004 c=0.0001 / train accuracy : 0.9894285714285714 / test accuracy : 0.8892380952380953 \n",
      "\n",
      "l1_ratio=0.30000000000000004 c=1e-05 / train accuracy : 0.9655714285714285 / test accuracy : 0.9003333333333333 \n",
      "\n",
      "l1_ratio=0.30000000000000004 c=1e-06 / train accuracy : 0.9332857142857143 / test accuracy : 0.9046825396825396 \n",
      "\n",
      "l1_ratio=0.30000000000000004 c=1e-07 / train accuracy : 0.8964285714285715 / test accuracy : 0.8853492063492063 \n",
      "\n",
      "l1_ratio=0.30000000000000004 c=1e-08 / train accuracy : 0.8457142857142858 / test accuracy : 0.8368571428571429 \n",
      "\n",
      "l1_ratio=0.4 c=100 / train accuracy : 0.995 / test accuracy : 0.8854920634920634 \n",
      "\n",
      "l1_ratio=0.4 c=10 / train accuracy : 0.9947142857142857 / test accuracy : 0.8855238095238095 \n",
      "\n",
      "l1_ratio=0.4 c=1 / train accuracy : 0.9948571428571429 / test accuracy : 0.8854603174603175 \n",
      "\n",
      "l1_ratio=0.4 c=0.1 / train accuracy : 0.9947142857142857 / test accuracy : 0.8855873015873016 \n",
      "\n",
      "l1_ratio=0.4 c=0.01 / train accuracy : 0.9945714285714286 / test accuracy : 0.8856031746031746 \n",
      "\n",
      "l1_ratio=0.4 c=0.001 / train accuracy : 0.9945714285714286 / test accuracy : 0.8862063492063492 \n",
      "\n",
      "l1_ratio=0.4 c=0.0001 / train accuracy : 0.9894285714285714 / test accuracy : 0.8892380952380953 \n",
      "\n",
      "l1_ratio=0.4 c=1e-05 / train accuracy : 0.9655714285714285 / test accuracy : 0.9003333333333333 \n",
      "\n",
      "l1_ratio=0.4 c=1e-06 / train accuracy : 0.9332857142857143 / test accuracy : 0.9046825396825396 \n",
      "\n",
      "l1_ratio=0.4 c=1e-07 / train accuracy : 0.8964285714285715 / test accuracy : 0.8853492063492063 \n",
      "\n",
      "l1_ratio=0.4 c=1e-08 / train accuracy : 0.8457142857142858 / test accuracy : 0.8368571428571429 \n",
      "\n",
      "l1_ratio=0.5 c=100 / train accuracy : 0.995 / test accuracy : 0.8854920634920634 \n",
      "\n",
      "l1_ratio=0.5 c=10 / train accuracy : 0.9947142857142857 / test accuracy : 0.8855238095238095 \n",
      "\n",
      "l1_ratio=0.5 c=1 / train accuracy : 0.9948571428571429 / test accuracy : 0.8854603174603175 \n",
      "\n",
      "l1_ratio=0.5 c=0.1 / train accuracy : 0.9947142857142857 / test accuracy : 0.8855873015873016 \n",
      "\n",
      "l1_ratio=0.5 c=0.01 / train accuracy : 0.9945714285714286 / test accuracy : 0.8856031746031746 \n",
      "\n",
      "l1_ratio=0.5 c=0.001 / train accuracy : 0.9945714285714286 / test accuracy : 0.8862063492063492 \n",
      "\n",
      "l1_ratio=0.5 c=0.0001 / train accuracy : 0.9894285714285714 / test accuracy : 0.8892380952380953 \n",
      "\n",
      "l1_ratio=0.5 c=1e-05 / train accuracy : 0.9655714285714285 / test accuracy : 0.9003333333333333 \n",
      "\n",
      "l1_ratio=0.5 c=1e-06 / train accuracy : 0.9332857142857143 / test accuracy : 0.9046825396825396 \n",
      "\n",
      "l1_ratio=0.5 c=1e-07 / train accuracy : 0.8964285714285715 / test accuracy : 0.8853492063492063 \n",
      "\n",
      "l1_ratio=0.5 c=1e-08 / train accuracy : 0.8457142857142858 / test accuracy : 0.8368571428571429 \n",
      "\n",
      "l1_ratio=0.6000000000000001 c=100 / train accuracy : 0.995 / test accuracy : 0.8854920634920634 \n",
      "\n",
      "l1_ratio=0.6000000000000001 c=10 / train accuracy : 0.9947142857142857 / test accuracy : 0.8855238095238095 \n",
      "\n",
      "l1_ratio=0.6000000000000001 c=1 / train accuracy : 0.9948571428571429 / test accuracy : 0.8854603174603175 \n",
      "\n",
      "l1_ratio=0.6000000000000001 c=0.1 / train accuracy : 0.9947142857142857 / test accuracy : 0.8855873015873016 \n",
      "\n",
      "l1_ratio=0.6000000000000001 c=0.01 / train accuracy : 0.9945714285714286 / test accuracy : 0.8856031746031746 \n",
      "\n",
      "l1_ratio=0.6000000000000001 c=0.001 / train accuracy : 0.9945714285714286 / test accuracy : 0.8862063492063492 \n",
      "\n",
      "l1_ratio=0.6000000000000001 c=0.0001 / train accuracy : 0.9894285714285714 / test accuracy : 0.8892380952380953 \n",
      "\n",
      "l1_ratio=0.6000000000000001 c=1e-05 / train accuracy : 0.9655714285714285 / test accuracy : 0.9003333333333333 \n",
      "\n",
      "l1_ratio=0.6000000000000001 c=1e-06 / train accuracy : 0.9332857142857143 / test accuracy : 0.9046825396825396 \n",
      "\n",
      "l1_ratio=0.6000000000000001 c=1e-07 / train accuracy : 0.8964285714285715 / test accuracy : 0.8853492063492063 \n",
      "\n",
      "l1_ratio=0.6000000000000001 c=1e-08 / train accuracy : 0.8457142857142858 / test accuracy : 0.8368571428571429 \n",
      "\n",
      "l1_ratio=0.7000000000000001 c=100 / train accuracy : 0.995 / test accuracy : 0.8854920634920634 \n",
      "\n",
      "l1_ratio=0.7000000000000001 c=10 / train accuracy : 0.9947142857142857 / test accuracy : 0.8855238095238095 \n",
      "\n",
      "l1_ratio=0.7000000000000001 c=1 / train accuracy : 0.9948571428571429 / test accuracy : 0.8854603174603175 \n",
      "\n",
      "l1_ratio=0.7000000000000001 c=0.1 / train accuracy : 0.9947142857142857 / test accuracy : 0.8855873015873016 \n",
      "\n",
      "l1_ratio=0.7000000000000001 c=0.01 / train accuracy : 0.9945714285714286 / test accuracy : 0.8856031746031746 \n",
      "\n",
      "l1_ratio=0.7000000000000001 c=0.001 / train accuracy : 0.9945714285714286 / test accuracy : 0.8862063492063492 \n",
      "\n",
      "l1_ratio=0.7000000000000001 c=0.0001 / train accuracy : 0.9894285714285714 / test accuracy : 0.8892380952380953 \n",
      "\n",
      "l1_ratio=0.7000000000000001 c=1e-05 / train accuracy : 0.9655714285714285 / test accuracy : 0.9003333333333333 \n",
      "\n",
      "l1_ratio=0.7000000000000001 c=1e-06 / train accuracy : 0.9332857142857143 / test accuracy : 0.9046825396825396 \n",
      "\n",
      "l1_ratio=0.7000000000000001 c=1e-07 / train accuracy : 0.8964285714285715 / test accuracy : 0.8853492063492063 \n",
      "\n",
      "l1_ratio=0.7000000000000001 c=1e-08 / train accuracy : 0.8457142857142858 / test accuracy : 0.8368571428571429 \n",
      "\n",
      "l1_ratio=0.8 c=100 / train accuracy : 0.995 / test accuracy : 0.8854920634920634 \n",
      "\n",
      "l1_ratio=0.8 c=10 / train accuracy : 0.9947142857142857 / test accuracy : 0.8855238095238095 \n",
      "\n",
      "l1_ratio=0.8 c=1 / train accuracy : 0.9948571428571429 / test accuracy : 0.8854603174603175 \n",
      "\n",
      "l1_ratio=0.8 c=0.1 / train accuracy : 0.9947142857142857 / test accuracy : 0.8855873015873016 \n",
      "\n",
      "l1_ratio=0.8 c=0.01 / train accuracy : 0.9945714285714286 / test accuracy : 0.8856031746031746 \n",
      "\n",
      "l1_ratio=0.8 c=0.001 / train accuracy : 0.9945714285714286 / test accuracy : 0.8862063492063492 \n",
      "\n",
      "l1_ratio=0.8 c=0.0001 / train accuracy : 0.9894285714285714 / test accuracy : 0.8892380952380953 \n",
      "\n",
      "l1_ratio=0.8 c=1e-05 / train accuracy : 0.9655714285714285 / test accuracy : 0.9003333333333333 \n",
      "\n",
      "l1_ratio=0.8 c=1e-06 / train accuracy : 0.9332857142857143 / test accuracy : 0.9046825396825396 \n",
      "\n",
      "l1_ratio=0.8 c=1e-07 / train accuracy : 0.8964285714285715 / test accuracy : 0.8853492063492063 \n",
      "\n",
      "l1_ratio=0.8 c=1e-08 / train accuracy : 0.8457142857142858 / test accuracy : 0.8368571428571429 \n",
      "\n",
      "l1_ratio=0.9 c=100 / train accuracy : 0.995 / test accuracy : 0.8854920634920634 \n",
      "\n",
      "l1_ratio=0.9 c=10 / train accuracy : 0.9947142857142857 / test accuracy : 0.8855238095238095 \n",
      "\n",
      "l1_ratio=0.9 c=1 / train accuracy : 0.9948571428571429 / test accuracy : 0.8854603174603175 \n",
      "\n",
      "l1_ratio=0.9 c=0.1 / train accuracy : 0.9947142857142857 / test accuracy : 0.8855873015873016 \n",
      "\n",
      "l1_ratio=0.9 c=0.01 / train accuracy : 0.9945714285714286 / test accuracy : 0.8856031746031746 \n",
      "\n",
      "l1_ratio=0.9 c=0.001 / train accuracy : 0.9945714285714286 / test accuracy : 0.8862063492063492 \n",
      "\n",
      "l1_ratio=0.9 c=0.0001 / train accuracy : 0.9894285714285714 / test accuracy : 0.8892380952380953 \n",
      "\n",
      "l1_ratio=0.9 c=1e-05 / train accuracy : 0.9655714285714285 / test accuracy : 0.9003333333333333 \n",
      "\n",
      "l1_ratio=0.9 c=1e-06 / train accuracy : 0.9332857142857143 / test accuracy : 0.9046825396825396 \n",
      "\n",
      "l1_ratio=0.9 c=1e-07 / train accuracy : 0.8964285714285715 / test accuracy : 0.8853492063492063 \n",
      "\n",
      "l1_ratio=0.9 c=1e-08 / train accuracy : 0.8457142857142858 / test accuracy : 0.8368571428571429 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# elasticent 에서 정확도를 출력하는 부분\n",
    "for i, l1_R in enumerate(l1_ratio_list):\n",
    "    trainScore_list = train_score_elasticent[i]\n",
    "    testScore_list = test_score_elasticent[i]\n",
    "    for c, trainScore, testScore in zip(C_list,trainScore_list, testScore_list):\n",
    "        print(\"l1_ratio={} c={} / train accuracy : {} / test accuracy : {} \\n\".format(l1_R, c, trainScore, testScore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction with plot // penalty=elasticnet l1_ratio=0.2 C=1e-06\n",
      "prediction 1 : 2\n",
      "prediction 2 : 6\n",
      "prediction 3 : 2\n",
      "prediction 4 : 2\n",
      "prediction 5 : 4\n",
      "prediction 6 : 3\n",
      "prediction 7 : 9\n",
      "prediction 8 : 8\n",
      "prediction 9 : 0\n",
      "prediction 10 : 8\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test set에서 랜덤하게 10개를 뽑은 후 이를 출력해서 예측값과 실제 값이 맞는지 틀린지 확인해보자\n",
    "rand_index = np.random.randint(low=0, high=len(X_test), size=10)\n",
    "\n",
    "l1_ratio_index = 1\n",
    "C_index = 8\n",
    "#logReg = log_models[C_index]\n",
    "logReg = logmodel_elasticent[l1_ratio_index][C_index]\n",
    "print(\"prediction with plot // penalty={} l1_ratio={} C={}\".format(Penalty,l1_ratio_list[l1_ratio_index],C_list[C_index]))\n",
    "for randin, i in zip(rand_index, range(1,len(rand_index)+1)):\n",
    "    predict = X_test[randin].reshape(1,-1)\n",
    "    print(\"prediction {} : {}\".format(i,logReg.predict(predict)[0]))\n",
    "    plt.subplot(2,5,i)\n",
    "    plt.imshow((X_test[randin].reshape(28,28)), cmap=plt.cm.gray_r, interpolation='nearest')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
